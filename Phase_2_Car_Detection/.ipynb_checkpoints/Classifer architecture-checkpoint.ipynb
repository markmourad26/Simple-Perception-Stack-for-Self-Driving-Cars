{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7337a13",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a6eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "import pandas as pd\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8b5b6",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction\n",
    "The YCrCb Color-Space</br>\n",
    "The YCrCb color space is derived from the RGB color space and has the following three compoenents.\n",
    "\n",
    "1. Y – Luminance or Luma component obtained from RGB after gamma correction.\n",
    "2. Cr = R – Y ( how far is the red component from Luma ).\n",
    "3. Cb = B – Y ( how far is the blue component from Luma )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d66fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Time taken to extract features (Spatial, Color Hist, HOG): 396.49858689308167\n"
     ]
    }
   ],
   "source": [
    "# Define the params dictionary\n",
    "params = {\n",
    "    'color_space': 'YCrCb',   # Can be RGB, HSV, LAB, HLS, YUV, YCrCb\n",
    "    'orient': 9,              # HOG orientations\n",
    "    'pix_per_cell': 8,        # HOG pixels per cell\n",
    "    'cell_per_block': 2,      # HOG cells per block\n",
    "    'spatial_size': (16, 16), # Spatial binning dimensions\n",
    "    'hist_bins': 24,          # Number of histogram bins\n",
    "    'hog_channel': 'ALL',     # Can be 0, 1, 2, or \"ALL\"\n",
    "    'spatial_feat': True,     # Spatial features on or off\n",
    "    'hist_feat': True,        # Histogram features on or off\n",
    "    'hog_feat': True,         # HOG features on or off\n",
    "}\n",
    "# Load pickled dataset\n",
    "with open('data.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "cars_train = data['cars_train']\n",
    "notcars_train = data['notcars_train']\n",
    "\n",
    "cars_test = data['cars_test']\n",
    "notcars_test = data['notcars_test']\n",
    "\n",
    "# Extract features\n",
    "print('Extracting features...')\n",
    "t1 = time.time()\n",
    "\n",
    "cars_features_train = extract_features(cars_train, params)\n",
    "notcars_features_train = extract_features(notcars_train, params)\n",
    "\n",
    "cars_features_test = extract_features(cars_test, params)\n",
    "notcars_features_test = extract_features(notcars_test, params)\n",
    "\n",
    "t2 = time.time()\n",
    "print('Time taken to extract features (Spatial, Color Hist, HOG): {}'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd1164c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature vector: 6132\n"
     ]
    }
   ],
   "source": [
    "print('Length of feature vector: {}'.format(len(cars_features_train[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b361e",
   "metadata": {},
   "source": [
    "## 2. Pre-process features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf68029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack([cars_features_train, notcars_features_train]).astype(np.float64) \n",
    "X_test = np.vstack([cars_features_test, notcars_features_test]).astype(np.float64) \n",
    "\n",
    "y_train = np.hstack([np.ones(len(cars_features_train)), np.zeros(len(notcars_features_train))])\n",
    "y_test = np.hstack([np.ones(len(cars_features_test)), np.zeros(len(notcars_features_test))])\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Sanity check\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b9a0d",
   "metadata": {},
   "source": [
    "## 3. Train the classifier (Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78cac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\car_env\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took: 28.0097\n",
      "Training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initiate the model\n",
    "clf = LinearSVC()\n",
    "\n",
    "print('Starting training...')\n",
    "start = time.time()\n",
    "# Fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print('Training took: {:.4f}'.format(end-start))\n",
    "print('Training accuracy: {:.4f}'.format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54174c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9820\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>884</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  884   19\n",
       "1   13  862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "print('Test accuracy: {:.4f}'.format(clf.score(X_test, y_test)))\n",
    "preds = clf.predict(X_test)\n",
    "df = pd.DataFrame(confusion_matrix(preds, y_test))\n",
    "print('Confusion Matrix:')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127907fc",
   "metadata": {},
   "source": [
    "## 4. Pickling the classifier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b10445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pickled the classifier data!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('classifier_data.p', mode='wb') as f:\n",
    "        pickle.dump({\n",
    "            'clf': clf,\n",
    "            'scaler': scaler,\n",
    "            'orient': params['orient'],\n",
    "            'pix_per_cell': params['pix_per_cell'],\n",
    "            'cell_per_block': params['cell_per_block'],\n",
    "            'spatial_size': params['spatial_size'],\n",
    "            'hist_bins': params['hist_bins'],\n",
    "            'color_space': params['color_space']\n",
    "        }, f)\n",
    "        \n",
    "except Exception as e:\n",
    "    print('ERROR: Failed to pickle the classifier and its params with exception: {}'.format(e))\n",
    "    \n",
    "print('Successfully pickled the classifier data!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
